Neural Network From Scratch 
he neural network is implemented using Python's classes. We have defined two activation functions - sigmoid and softmax. Sigmoid for intermediate layers and softmax for the final layer. Cross entropy as loss function is used 
Finally we train the network for a max of 8000 epochs with a convergence early stopping criteria. If the loss goes lower than 0.05, we stop training and return the predictions. 
 
